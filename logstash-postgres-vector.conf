input {
  # PostgreSQL JDBC Input with Vector Search Support
  jdbc {
    jdbc_driver_library => "/usr/share/logstash/drivers/postgresql-42.7.1.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://postgres:5432/${POSTGRES_DB}"
    jdbc_user => "${POSTGRES_USER}"
    jdbc_password => "${POSTGRES_PASSWORD}"
    
    # Schedule - run every 1 minute for testing
    schedule => "*/1 * * * *"
    
    # Query users table
    statement => "SELECT id, name, email, created_at, 'users' as table_name FROM public.users ORDER BY id"
    
    # Add metadata with vector index prefix
    add_field => { 
      "[@metadata][index]" => "${VECTOR_INDEX_PREFIX:postgres-vector}"
      "[@metadata][doc_type]" => "user"
      "data_source" => "postgresql"
      "vector_strategy" => "${VECTOR_EMBEDDING_STRATEGY:builtin}"
    }
    
    # Tag for identification
    tags => ["postgresql", "users", "vector_enabled"]
  }
}

filter {
  # Handle different embedding strategies
  if "vector_enabled" in [tags] {
    
    # Prepare content for embedding (always done)
    mutate {
      add_field => { 
        "content_for_embedding" => "%{name} %{email}"
      }
    }
    
    # External API embedding generation (OpenAI)
    if [vector_strategy] == "openai" {
      http {
        url => "https://api.openai.com/v1/embeddings"
        verb => "POST"
        headers => {
          "Authorization" => "Bearer ${OPENAI_API_KEY}"
          "Content-Type" => "application/json"
        }
        body_format => "json"
        body => {
          "input" => "%{content_for_embedding}"
          "model" => "${OPENAI_MODEL:text-embedding-3-small}"
        }
        target_body => "openai_response"
        add_field => { "external_embedding_attempted" => "true" }
      }
      
      # Extract embedding from OpenAI response
      ruby {
        code => '
          begin
            response = event.get("openai_response")
            if response && response["data"] && response["data"][0]
              embedding = response["data"][0]["embedding"]
              event.set("content_embedding", embedding)
              event.set("embedding_success", true)
              event.set("embedding_dims", embedding.length)
            else
              event.set("embedding_success", false)
              event.set("embedding_error", "No embedding in response")
            end
            event.remove("openai_response")
          rescue => e
            event.set("embedding_success", false)
            event.set("embedding_error", e.message)
          end
        '
      }
    }
    
    # HuggingFace API embedding generation
    else if [vector_strategy] == "huggingface" {
      http {
        url => "https://api-inference.huggingface.co/pipeline/feature-extraction/${HUGGINGFACE_MODEL:sentence-transformers/all-MiniLM-L6-v2}"
        verb => "POST"
        headers => {
          "Authorization" => "Bearer ${HUGGINGFACE_API_KEY}"
          "Content-Type" => "application/json"
        }
        body_format => "json"
        body => {
          "inputs" => "%{content_for_embedding}"
        }
        target_body => "hf_response"
        add_field => { "external_embedding_attempted" => "true" }
      }
      
      # Extract embedding from HuggingFace response
      ruby {
        code => '
          begin
            response = event.get("hf_response")
            if response.is_a?(Array) && response.length > 0
              embedding = response[0]
              event.set("content_embedding", embedding)
              event.set("embedding_success", true)
              event.set("embedding_dims", embedding.length)
            else
              event.set("embedding_success", false)
              event.set("embedding_error", "Invalid HF response format")
            end
            event.remove("hf_response")
          rescue => e
            event.set("embedding_success", false)
            event.set("embedding_error", e.message)
          end
        '
      }
    }
    
    # Local embedding service
    else if [vector_strategy] == "local" {
      http {
        url => "${LOCAL_EMBEDDING_URL:http://embedding-service:8080}/embed"
        verb => "POST"
        headers => {
          "Content-Type" => "application/json"
        }
        body_format => "json"
        body => {
          "text" => "%{content_for_embedding}"
        }
        target_body => "local_response"
        add_field => { "external_embedding_attempted" => "true" }
      }
      
      # Extract embedding from local service response
      ruby {
        code => '
          begin
            response = event.get("local_response")
            if response && response["embedding"]
              embedding = response["embedding"]
              event.set("content_embedding", embedding)
              event.set("embedding_success", true)
              event.set("embedding_dims", embedding.length)
            else
              event.set("embedding_success", false)
              event.set("embedding_error", "No embedding in local response")
            end
            event.remove("local_response")
          rescue => e
            event.set("embedding_success", false)
            event.set("embedding_error", e.message)
          end
        '
      }
    }
    
    # For built-in and disabled strategies, embedding handled by ingest pipeline
    else {
      mutate {
        add_field => { "embedding_handled_by" => "elasticsearch_ingest_pipeline" }
      }
    }
  }
  
  # Standard processing
  mutate {
    add_field => { 
      "ingestion_timestamp" => "%{@timestamp}"
      "environment" => "development"
    }
  }
  
  # Convert created_at timestamp
  if [created_at] and [table_name] == "users" {
    date {
      match => [ "created_at", "yyyy-MM-dd HH:mm:ss.SSSSSS", "yyyy-MM-dd HH:mm:ss" ]
      target => "created_timestamp"
    }
  }
}

output {
  # Debug output based on strategy
  if [vector_strategy] == "builtin" {
    stdout { 
      codec => line { 
        format => "BUILTIN VECTOR: %{name} (%{email}) - Strategy: %{vector_strategy}" 
      }
    }
  } else if [vector_strategy] in ["openai", "huggingface", "local"] {
    stdout { 
      codec => line { 
        format => "EXTERNAL VECTOR: %{name} - Strategy: %{vector_strategy} - Success: %{embedding_success} - Dims: %{embedding_dims}" 
      }
    }
  } else {
    stdout { 
      codec => line { 
        format => "NO VECTOR: %{name} (%{email}) - Strategy: %{vector_strategy}" 
      }
    }
  }
  
  # Send to Elasticsearch using vector-enabled index
  elasticsearch {
    hosts => ["https://es01:9200"]
    user => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    cacert => "certs/ca/ca.crt"
    
    # Use configurable index prefix
    index => "%{[@metadata][index]}-%{+YYYY.MM.dd}"
    document_type => "%{[@metadata][doc_type]}"
  }
}
